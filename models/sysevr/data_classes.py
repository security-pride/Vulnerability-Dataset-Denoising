from dataclasses import dataclass
from typing import List

import numpy
import torch


@dataclass
class SYSSample:
    tokens: numpy.ndarray
    label: int
    n_tokens: int
    idx: int
    flip: bool


class SYSBatch:
    def __init__(self, samples: List[SYSSample]):
        self.gadgets = torch.cat([
            torch.tensor(sample.tokens, dtype=torch.float32)
            for sample in samples
        ],
                                 dim=0)  # [total word; embedding size]

        self.labels = torch.from_numpy(
            numpy.array([sample.label for sample in samples]))
        self.tokens_per_label = torch.from_numpy(
            numpy.array([sample.n_tokens for sample in samples]))
        self.idxs = torch.from_numpy(
            numpy.array([sample.idx for sample in samples]))
        self.flips = torch.from_numpy(
            numpy.array([sample.flip for sample in samples]))
    def __len__(self) -> int:
        return self.labels.size(0)

    def pin_memory(self) -> "SYSBatch":
        self.gadgets = self.gadgets.pin_memory()
        self.labels = self.labels.pin_memory()
        self.tokens_per_label = self.tokens_per_label.pin_memory()
        self.idxs = self.idxs.pin_memory()
        self.flips = self.flips.pin_memory()
        return self

    def move_to_device(self, device: torch.device):
        self.labels = self.labels.to(device)
        self.tokens_per_label = self.tokens_per_label.to(device)
        self.gadgets = self.gadgets.to(device)
        self.idxs = self.idxs.to(device)
        self.flips = self.flips.to(device)